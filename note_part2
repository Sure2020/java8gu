388 Gu Part2
51. 如何存ip地址，分为ipv4/6。   都有两种，用字符串或者整数。字符串比较占空间，而且比较大小也比整形慢。
字符串，没啥可说的。
整形，mysql中ipv4用binary(4)，也就是4字节，32 位存，先各段转为二进制，再去掉点号，最后二进制转为整型。
ipv6用binary(16)表示，也就是16*8=128字节。

52. rpc调用，客户端超时，服务端没超时，怎么回事。网络延迟或丢包；   客户端超时时间比服务端短

53. 为啥不建议用mq延迟队列实现订单到期关闭。
每个消息都要一个延迟消息，即使这个订单会立即关闭。仍然会创建延迟消息，消耗资源。   mq本身不支持延迟消息，即使支持，也有限制比如限制最长延迟时间。   消息有延迟。

54. 为什么不要在事务中做外部调用。因为外部调用不可控，如果外部调用性能差，回复延迟高，甚至报错等，会拖慢整个事务的性能，而且出错了不能回退。
建议是将事务和外部调用分离。   如果外部调用必须和数据库操作紧密集成，那可以使用补偿事务，用来处理外部调用失败的情况，用来撤销已经执行的外部调用。  

55. 如何做平滑的数据迁移。写旧读旧---双写读旧，可以借助flink\canal等数据同步工具实现，也可以自己写代码实现，先写旧库，成功后再写新库。---增量数据核对---存量数据迁移---存量数据核对---双写读新（灰度切流）---全量数据核对---写新读新（灰度切流）。

56. 使用分布式锁的时候，锁加在事物外面还是里面。这就是个加锁粒度的问题，建议锁加外面。防止即使加了锁仍然出现脏数据的问题。

57. 加了分布式锁，不就影响并发了吗，怎么回复这个问题。
加锁，是为了当时多个请求同时到达争抢资源然后发生意向不到的错误，出了错误还要处理，这反而影响了并发。加分布式锁，虽然拦住了这个用户的请求，但使得其他用户的请求得以正常执行，减少出错，这反而是提高了并发。

58. 数据库的乐观锁，悲观锁，和redis的分布式锁，区别和使用场景？悲观锁select for update实现，会锁表，适合并发高，更新和删除多的场景。是悲观地认为并发会发生，属于先加锁再干活。
乐观锁，往往通过版本号实现，其实在更新时也会加行级锁。认为并发不会发生，是先干活再加锁。
其实数据库的悲观锁和redos的分布式锁，作用差不多。其实redis分布式锁性能更好，支持锁重入和锁延期等。悲观锁有可能锁表。

59. 为什么很多公司禁止物理删除。
数据留痕，方便做数据分析，报表，定位问题等。
合规，很多业务比如金融，是要求要有历史数据方便回溯的。
性能，物理删除会影响数据库性能。
碎片，有时候物理删除了并不会立即删除，造成内存碎片。

60. 为什么不用分布式锁实现秒杀，(而是用lua脚本)。答案是，没必要！用lua脚本和使用redis分布式锁，性能差不多，而且可以利用lua脚本的原子性，避免超卖。reids锁的话还要查找redis缓存中的库存，判断是否超卖，更新缓存，判断数据库的库存，更新数据库等。需要和组件多次建立连接。业务变复杂。

lua脚本有原子性，是因为redis会封装成一个单独的事务，执行期间有其他事务，则等待。

61. 为什么不用BlockingQueue做消息队列。
不支持分布式，无法持久化，没有高级特性支持，比如消息确认，延迟消息等。没有管理和监控工具。
性能也差，kafka专门做过性能优化。

62. spring event和mq的区别。
1）共同点，都是发布订阅模式，都支持一对多，都可以异步处理。
2）不同点，spring event不支持跨jvm，不支持分布式，没有诸如延迟消息等丰富的功能，没有失败重新发送的功能，性能不如专门做过优化的mq。
如果单纯想达到服务内异步调用的效果，用event足够，如果需要分布式等高级功能，选mq。

63. 怎么基于redis的zset实现秒级排行榜。
1）如果只要日排行，周排行，月排行，利用定时任务定时拉取数据计算即可。
2）如果要实现秒级排行或实时排行，可借助redis的zset。score是积分，member是用户唯一标识。用zreverangeWithScore就能快速得到排行结果。
优化：想实现当score相同，就按创建时间排序，可以向score中存浮点数，其中整数部分是积分，小数部分是时间戳，即，score=积分+1-时间戳/1e13。可实现积分相同的，先达到的排行靠前。

64. redis的zset是什么实现的。
zset，底层实现就是用了大名鼎鼎的跳表（skiplist）。和压缩列表（zipList或listPack）。查找，修改，删除，时间复杂度都为ologn
当元素数大于128或元素值大于64字节，用skiplist。
还用到了dict，元素为key，得分为value。查找，修改，删除时间复杂度都为o1。


65. 一定要限流吗，不应该尽力服务客户吗，为啥不加机器。
1-限流是为了防止不正常的流量，如黑客攻击，限制了非正常流量，才能更好地为客户服务，也保护自己
2-保护他人，上游加了机器，下游也承受不住这么高的并发。

66. 大型电商订单系统，怎么分库分表。
1-分库，分表，分库分表，是三件不同的事，当客户端过多，超过数据库的最大连接数，或者达到了单例数据库的cpu内存等资源瓶颈，这时候要考虑分库，将连接负载到其他节点，减轻单个数据库节点的压力
2-分表，当数据量过大，比如超过2000万条，会影响数据库操作性能，比如查询速度下降，就要考虑分表。

3-分库策略，垂直分库，就是按业务分，比如订单库，商品库，用户库，库存库等。水平分库（分表），就是把数据均分到其他库，比如1000万数据分到5个库，每个库200万条。
4-分表策略，垂直分表，比如将10个字段的表分成分表有5个字段的2个表。

5-分多少，表的数量，可以按（当前数据量+每年增长量*保存年数）/2000万，再向上取2的次幂。库的数量，经验值是表数量/8，如果分表的数量本身就是小于8的，那直接分库数量=分表数量

6-分表字段怎么选择，按时间分表，比如2023年，2024年。按买家ID分，可以避免按卖家ID分带来的数据倾斜问题。
那卖家查询怎么查？可以利用数据同步工具，如监听binlog或flink工具，再生成一个卖家表。
那订单查询怎么查？可以用基因法，就是订单号中包含分表id和买家id。

7-分表算法有哪些，一致性哈希，大名鼎鼎，（但用的较少！）就是一个圆环，将表id按哈希函数映射到环上，将表所在节点也哈希并映射到环上，然后顺时针查找节点，即可找到数据所在节点。
再就是根据买家id取模。比如买家id是12345，分4张表，分表结果就是12345%4.如果分表字段不是数字，那就哈希再取模。
