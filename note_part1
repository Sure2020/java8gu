8 GU Part1
1.uuid，基于mac地址和时间戳，
坏处，可读性差，不利于排序，容易泄露mac地址

2.雪花算法，基于时间戳，数据中心标识，机器标识，序号
好处，自增，方便排序
坏处，数据迁移时需要改数据中心号和机器号，易重复。依赖时间戳，如果时钟回拨，可能重复。

3.订单到期关闭，推荐用redission+redis。用redission的rdelayedQueue分布式延迟队列，将数据+延迟队列放到zset，到时间，就取出数据返回给服务；
简单点就定时任务

4.订单到期关闭，不建议用Mq，是因为1.每个订单都创建延迟队列，消耗资源，而且会有大量无效消息，不管是否需要延迟；2.延迟队列发送消息本身有延迟，而且不能保证100%不丢数据。3.有些mq不支持延迟队列，即使支持，也有一些限制比如限制最大延迟时间。

5.每天100w次登录请求，4C8G服务器如何做JVM调优。
堆大小，总内存的一半。
新生代较多，用jdk9默认垃圾回收器G1
（待补充）

6.业务突然增长100QPS怎么办。1）.受到DDOS（分布式拒绝服务），根据ip、设备信息等识别攻击源,在防火墙服务器上用acl访问控制列表；2）蹭到热点，就临时加服务器，加带宽就行了。3）长期的增长，要考虑多层缓存，比如客户端缓存+CDN+服务端redis缓存；分布式、负载均衡；分库分表等

7.不用redis分布式锁，如何防止用户重复点击。1)按钮置灰;2)布隆过滤器；

8.what is布隆过滤器，快速判断一个元素是否可能存在于一个集合，即bit数组中。原理是通过多个哈希函数，将一个元素映射成多个位，然后这些位赋值1。判断元素是否存在时，仍然通过多个哈希函数计算。如果有某位不为1，一定不存在，如果都为1，大概率存在。
应用场景就是需要过滤的场景，比如防止重复点击，比如缓存系统

####让你实现消息队列，你会考虑哪些细节

9.kafka的架构，生产者，消费者，broker。一个主题有多个分区，合适的分区规则可以保证消息均匀分布在各个分区，保证了负载均衡和水平扩展。每个分区可以有多个副本，分为主副本和从副本。消费者只访问主副本，从副本只用来备份。
zookeper用来保存集群信息，分区信息等

9.1 kafka怎么保证消息不丢失？生产者，发送消息时注册回调，在发送失败后重试。broker，把消息持久化。消费者，在消费成功后再提交偏移量，推荐将偏移量自动提交改为false

9.2 kafka为什么这么快。消息发送时，批量发送，压缩消息，异步发送。消息存储时，用零拷贝（尽量减少数据拷贝次数以及cpu参与拷贝的次数，有专门底层方法。），磁盘顺序写入，比随机写入快。消费者，并行消费，不同消费者可以独立消费不同分区。批量拉取。

9.3, kafka怎么实现顺序消费，1）一个topic只创建一个分区;2) 发送消息时指定分区

9.4 kafka怎么保证只消费一次，消费者都加入至少一个消费者组，一个消息只会被同一个消费者组中的一个消费者消费；  消费者手动提交自己控制offset，自己跟踪已消费的消息，比如通过一些幂等机制，确保不重复消费。

9.5 kafka的消费者组的作用，同一消费者组中的消费者，可消费同一topic下的不同分区，实现了负载均衡。也方便水平扩展。

10.rocketmq的架构，生产者消费者broker，一个主题可以对应多个消息队列。nameserver用来保存元信息，比如broker地址，topic和队列信息等。
rocketmq的消息分发有广播消费和集群消费。广播消费会保证每个消费者都消费一次，但不负责消费失败的重传。集群消费则是有一个消费者消费即可。
每条消息只会发往一台机器。集群模式应用较多。多实例？

10.1  rocketmq怎么保证消息不丢失，生产者，用同步发送。broker，用同步刷盘，消费者，消费成功再回复ack，

10.2 rocketmq怎么顺序消费，生产者只发送到同一个队列，同队列消息有序，队列队列，先进先出嘛！消费者顺序消费，不要并行消费。

10.3 rocketmq怎么保证只消费一次，首先消费者消费后会返回ack，消息队列收到消息后会删除消息。
同时消费者本身也要做幂等措施保证不重复消费，比如要求生产者在消息中加入唯一索引。

10.4 rocketmq消息堆积了怎么办，增加消费者，增加消费者处理速度，减缓生产者生产速度，清理过期消息，

11.rabbitmq的架构,生产者消费者，vhost，虚拟主机，类似于操作系统中的名命名空间，用来在不同vhost之间隔离资源。
exchange交换器是消息接收和路由中心，queue队列，保存消息，等待消费。

11.1 rabbitmq如何保证消息不丢。队列和交换机的持久化。durable设置为true。

12.推模式和拉模式。推模式，就是服务端建立长连接，主动向消费者推，实时性高，但有可能造成消费端消息堆积。拉模式，消费者轮询，主动拉取消息，这样可以自由控制拉去频率，但轮询也需要消耗资源。
一般是长轮询，消费者向中间件发起一个长轮询，有消息则返回，没消息则不关闭连接而是等一会儿。

13.分布式事务，是为了保证生产者消费者模式的业务能全部成功或全部回滚。

14.如何解决接口幂等。一锁二判三更新。二判：根据流水表，唯一性索引，状态机等判断操作是否重复。
状态机：就是记录目标各种状态的一种思想吧，比如将订单id和状态写入一个表，并随业务推进，不断更新订单的状态。

#####库存扣减如何避免超卖，少卖
15.避免超卖：用redis的lua脚本，扣减库存前先判断库存。利用lua脚本的原子性和redis的高性能。
避免少卖：产生原因，在redis缓存中扣减后，发送消息通知数据库扣减，但在这个环节扣减失败，少卖产生。解决方法，用对账机制。比如定时根据订单流水统计，然后和数据库比对。

16.如何利用redis实现朋友圈点赞。利用redis的zset，key为本朋友圈id，value为其他用户id，score为点赞时间。用zrevrangebyscore可以按score排序。
---zset的应用，排行榜，关注列表，朋友圈点赞

17. redis的zset怎么实现排行榜，且分数相同时按时间排序。用户得分存到score中，value是用户id。因为zset默认是用score排序，再用value排序。如果想用时间排序，就在score中做文章，将score设置成小数，整数部分是得分，小数部分是时间戳。即score=分数+时间戳/1e13.如果想改变排序方向，就用score=分数+  1-时间戳/1e13

18.怎么实现查找附近的人的功能。利用redis的geolocation数据结构。可存储经度纬度和value,value常为地点名称或者人员名称。用georadius可查看指定半径内所有member的信息。

19. kafka单分区单消费者，怎么提高吞吐量。其实有效手段是多分区多消费者，单如果不能增加分区和消费者，那就从消费者本身入手：异步消费、多线程、消息压缩或组合

20.订单在11：00超时关闭，但也支付成功，怎么办。1）做状态流转校验，只有在支付中的订单，可以流转到支付成功或超时关闭。并在更新库时加乐观锁避免并发；  
 如果支付成功处理成功，支付超时处理失败，就这样，符合业务逻辑。支付超时的请求再进行重试的花，直接拒绝掉即可。
如果支付成功处理失败，支付超时处理成功，也就是明明人家支付成功了，但最后认为是超时没成功。这时候就要原路退回款项。可以感知到这种情况，就是支付成功处理失败后，肯定要重试吧，结果发现订单已关闭，就触发退款逻辑即可。
或者加分布式锁，处理好并发，尽量避免这种情况。

20.1如果多渠道支付成功。1）还是状态流转的控制，只有当订单状态是支付中，才可以变成支付成功。如果支付宝已支付成功，订单状态变为支付成功，这时候微信也支付成功了，如果在处理支付成功的回调时，检查订单状态为已完成，如果渠道号一样，就返回成功。渠道号不一致就触发退款逻辑即可。

21. 如果解决重复消费，重复下单。总之用幂等的思想解决即可
重复消费：和消息生产者约定一个幂等号，比如消息体中的一个字段。消费时一锁二判三更新（处理）
重复下单：用token，每次访问页面都想服务的申请token，并在后续请求中携带token，服务端收到请求并成功处理后，就在redis中删除该token，那么后面重复提交的请求就被认为是无效的。这样还可以防止别人恶意刷接口

22.分布式id生成方案,uuid，雪花算法，数据库自增，redis的incr命令自增。一些开源工具比如百度uidgenerator,美团leaf，滴滴tinyid等。

23. 你如何进行sql调优。比如排查慢sql。先通过explain观察执行计划，重点关注type,key,extra这3列。
key一定要有值，不能是null
type应该是ref,eq_ref,range,const等
extra如果是null，usering index,user index condition都可以

24.索引失效的情况
1）sql语句的where字段，没创建索引，或者违反最左原则。
2）索引区分度不高，首先索引区分度的意思是索引值和总行数的比例。越高越好。反例是用性别字段当索引，只有男女两种取值。
3）表太小，优化器认为扫描全表成不不高的时候，就不走索引
4）对索引字段用了函数计算

25.为什么不建议用多表join，因为就是个嵌套循环。
不用join怎么做关联查询？1）先从数据库中把数据读到内存，在二次查询关联；2）数据冗余，就是把重要字段在多个表中都存一下；3）宽表，就是把多张表做成一个表。

26.区分度不高的字段做索引一定没用吗，不一定，比如性别字段，加速男女比例95:5，只查女，那也可以过滤很多数据。这种常用在failed和success状态的过滤

27.用枚举实现单例。直接 public enum Singleton { INSTANCE; }。因为底层的话枚举元素都是用static修饰的，enum和class一样是Java关键字。static类的属性在类被加载时初始化，而类的加载是classloder类的loadclass方法实现的，该方法自己保证了线程安全。于是说枚举天生线程安全。

27.1 如何破坏单例，用反射，去调用创建实例的方法；或者用序列化+反序列化时通过unsafe方法创建。
而枚举的反序列化不是通过unsafe，也不是通过反射，所以无法破坏。

28. 40亿个qq号，限制1G内存，怎么去重。用位图？bitmap 至于怎么映射，不是简单的用二进制的方法去映射，有专门的算法，参见：https://blog.csdn.net/lucky52529/article/details/90172264

28.1 如果位图中存稀松的数，会造成内存浪费，可以将32位整数拆分成高低16位，高16位相同的数放一起，低16位形成一个bitmap。以后成熟框架：roaringBitMap

29.本地缓存，guava cache，caffeine

30.多级缓存，客户端缓存，cdn，nginx，缓存黄牛ip等，本地缓存，存不常变的数据比如用户信息，分布式缓存

31.b+树为什么单表2000万要考虑分表，因为3层树大约能存2000万，否则高度增加，影响性能

32.b+树和跳表，b+树方便范围查询和倒序查询，
顺序存放方便排序，
只在叶子节点存储数据，用的是连续的磁盘空间，方便磁盘预读。总之是磁盘友好型。

跳表，实现简单，是分散存储的，但内存不介意这么存。缓存增删频繁，不用考虑树的重新平衡。

33.接口响应慢，排查，先用监控系统发现慢的现象和业务。用arthas分析。比如trace命令看接口耗时。可以看到接口内各个逻辑的耗时。

34.arthas怎么动态修改代码。找到类，反编译类，修改，重新编译并运行。。。。。。。。。

35.怎么做对账。写代码核对，定时任务，不推荐，数据过大时耗资源，容易oom。
写sql核对。写在哪里？
离线数据仓，
在线库，去备库中写。
准实时库，监听binlog同步数据到实时数仓。
etl，抽取，转换，加载工具，如datax。
flink，流处理框架。

36.千万级大表怎么做数据清理，比如删除300天以前的数据。分批次，分时间段的进行。先根据索引或者非空唯一键取出最大最小值，再按段，分批分析并分批删除。还可以指定在业务不忙的时候进行。

37.b+树和b树区别，就两点，数据存储位置，前者只存在叶子节点，且叶子节点间有双向指针，方便范围查询。前者磁盘友好型，那内存存储，后者一定好吗，不一定，虽然后者在随机查询上有优势，因为非叶子节点也存数据。但前者高度更小。
mongodb在新版本，3.2以后，也采用b+树为默认存储引擎的数据结构了

38. mysql 怎么做热点数据更新。
1）先更新redis缓存，再异步更新数据库。（改造成本高）
2）将热点数据拆分到不同的库，分摊压力（改造成本高）
3）请求合并，将多个请求合并成一个，比如对积分的改变。（有延迟）
4）update改成insert，先插入一条记录，再用流水对账的方式，对库存进行更新（有延迟）
5）对数据库进行改造，将原本update需要在数据库层面排队改为在业务执行层排队。
总之就是排队（先更新redis这种异步方式也算）、拆分、合并

两个线上问题，数据库连接池满以及数据库CPU打满，都是因为update语句导致锁等待。一个是通过改造数据库解决，一个是通过合并数据库操作解决（一个合案的业务）

39. 与外部系统交互，怎么防止被拖垮。
熔断，限流，降级。都用阿里sentinal

异步，通过定时任务或者消息中间件交互，比如下单后顺便买了运费险。

文件交互，比如寄快递，可以先申请一批运单号，先用，然后批量定时通知快递公司，或者用文件形式上传到ftp服务器。

超时，超过2分钟就报错，比如查看人员信息，超时就报陌生人或者查询失败。

熔断，多个支付渠道，如果银联不可用，干脆停掉这个选项，可用后再恢复

40.如何解决热key问题。
可以预测的，就预热，比如双十一大促；
没法预热的就事中解决，比如用工具识别热key；用多级缓存。·热key备份，就是搞个redis集群；热key拆分，就是把一个key加后缀变成多个key，并根据请求的不同，映射到这些加后缀的key，最终将请求分发到不同的实例，达到减轻redis压力的目的。

40.1 redis缓存的过期策略，有定期删除和惰性删除两种。
40.2 redis缓存的内存淘汰策略，就是当redis存满以后，怎么淘汰，有LRU,LFU等。

41. 一个接口3000QPS,RT 200ms,需要几台机器。 先算单机器单线程的吞吐量：1000ms/200ms = 5个/秒，假设服务器tomcat，默认200个线程，那单机器吞吐量就是5*200就是1000个/秒，扛3000就需要3台机器，至少。

42. 数据库逻辑删除后，怎么做唯一性约束，能保证用户可以多次开通
扩展：如果允许物理删除，那后面做报表仍然需要历史用户数据，就搞个service_history表，或者离线数仓同步数据时只同步insert和update,不同步delete。
如果不允许物理删除，那就is_deleted>0都表示已删除，或者新增一个字段delete_time表示时间，这样就 可以用user_id+ product_id + is_deleted 或 再加上delete_time做唯一索引。

44. 数据表很大以后，必须分库分表吗。不到万不得已，不要分库分表。会带来很多问题，比如无法全表扫描，无法分页，无法跨库事务等。
考虑优化sql，利用缓存减缓压力，分布式数据库等。

43. 缓存如何预热。启动时加载，比如监听applicationReayEvent事件。   定时加载，我的想象是定时分析热key并加载。   利用咖啡因框架的缓存加载器，在缓存为空时自动加载。

45. 百万级数据从excel导入数据库，用easyExcel，将数据分散在不同的sheet，然后用多线程同时读取不同的sheet，分批读取到内存，用线程安全的“并发链表”保护内存中的数据。做好数据教验后批量写入数据库，如果有失败的，就记录日志。

46.如何做跨库join，首先不建议join。
如果两个库在同一个实例，可以在join时指定库名即可。  
 冗余字段。     
 内存中做join。
  宽表，借助ETL工具搞到同一个表中。  
 借助第三方数据库，比如监听binlog拉取数据到同一个库。   或者flink数据同步工具。      
或把数据搞到ES里，借助ES的内置工具。

47.和其他公司做数据交互，需要注意什么。
安全，协议加密，内容加密。身份检验。
效率，专线，数据压缩，用url代替流媒体内容

48. 4c8g的机器，各项指标多大算正常，一般cpu保持在30%以下属于比较空闲，3-7属于中等负载。
内存，硬盘，在80以内都可以接受。
JVM堆内存在4-6G，磁盘IO较平稳，没有长时间高峰。
GC次数，新生代一分钟一次，每次50ms以内
老年代一周一次，每次一秒内。

49.  数量多的小资源机器，和数量少的大资源机器，怎么选。
数量多的机器， 优点是容错能力强，负载更均衡，
数量少性能高的机器，单机瓶颈高，GC次数少。

50. 慢sql问题，用了索引，但优化器改用了主键索引，结果很慢。首先因为语句中有order by 主键,mysql 会更倾向于不用自定义的索引，而是用主键索引，因为索引已经有序，可以避免再去排序。

总之，因为用了主键做排序，所以优化器更倾向于用主键做索引。

但，由于有id>xxx的条件，查出来的数据仍然有很多，区分度不高，于是很慢。

解决：from 的时候加force index
或者，换一个排序字段，比如create_time，记得把create_time也加到联合索引中